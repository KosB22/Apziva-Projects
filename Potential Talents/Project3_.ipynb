{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1a58fd",
   "metadata": {},
   "source": [
    "# Candidate Ranking Using Relevance Feedback and Text Features\n",
    "## üß† Objective\n",
    "In this project, we aim to rank candidates based on a combination of structured attributes and unstructured text fields using techniques like TF-IDF and Rocchio relevance feedback. This ranking model is useful for applications like recruitment platforms or academic search engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d033e",
   "metadata": {},
   "source": [
    "## üìã Background\n",
    "Candidate data typically includes both numeric fields (e.g., scores, connection count) and free-form text (e.g., titles, bios). To effectively rank candidates, we integrate these two types of data into a unified feature matrix. This allows for leveraging the classic vector-space retrieval model + relevance-feedback techniques to rank candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b94e8-f70a-4663-9e3f-11c361c8a3a2",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    " - Build your TF‚ÄìIDF matrix, compute pure text‚Äêsimilarity to ‚Äúaspiring HR.‚Äù\n",
    "\n",
    " - Create a normalized bonus from connections.\n",
    "\n",
    " - Mix text + connections into initial_score.\n",
    "\n",
    " - Run Rocchio only on the TF‚ÄìIDF features (X_text) to get a new query vector.\n",
    "\n",
    " - Recompute text‚Äêsimilarity with the updated query, then add the same connection bonus to get your final updated_score.\n",
    "\n",
    "By tuning alpha vs. beta you control how much weight ‚Äúconnections‚Äù have vs. pure text match‚Äîwhile keeping all your relevance-feedback math in the clean TF‚ÄìIDF space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233adea",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Data Overview\n",
    "We'll load and inspect the dataset, identify missing values, and review the structure of text vs. numeric fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9508eb-34c7-4189-beaa-b78d097bc435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "385aa3dd-2fcb-42f7-b1cd-1e5c1919c72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'job_title', 'location', 'connection', 'fit']\n",
      "   id                                          job_title  \\\n",
      "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
      "1   2  Native English Teacher at EPIK (English Progra...   \n",
      "2   3              Aspiring Human Resources Professional   \n",
      "3   4             People Development Coordinator at Ryan   \n",
      "4   5    Advisory Board Member at Celal Bayar University   \n",
      "\n",
      "                              location connection  fit  \n",
      "0                       Houston, Texas         85  NaN  \n",
      "1                               Kanada      500+   NaN  \n",
      "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
      "3                        Denton, Texas      500+   NaN  \n",
      "4                       ƒ∞zmir, T√ºrkiye      500+   NaN  \n",
      "Number of candidates: 104\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "# 1. read the file as a DataFrame\n",
    "df = pd.read_excel(\"potential-talents.xlsx\")\n",
    "print((list(df.columns)))\n",
    "print(df.head(5))\n",
    "print(\"Number of candidates:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8227f862-5089-47d0-99ce-7e1df955b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "id              0\n",
      "job_title       0\n",
      "location        0\n",
      "connection      0\n",
      "fit           104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba5377",
   "metadata": {},
   "source": [
    "## üßπ Text & Numeric Preprocessing\n",
    "We convert all text and numeric fields into a single sparse matrix for model compatibility. This includes fitting TF-IDF on cleaned text fields and preparing a regression target score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe28e6e-aa3b-4d9e-ae89-667cd1fcbb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          job_title  \\\n",
      "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
      "1   2  Native English Teacher at EPIK (English Progra...   \n",
      "2   3              Aspiring Human Resources Professional   \n",
      "3   4             People Development Coordinator at Ryan   \n",
      "4   5    Advisory Board Member at Celal Bayar University   \n",
      "\n",
      "                              location connection  fit  \\\n",
      "0                       Houston, Texas         85  NaN   \n",
      "1                               Kanada      500+   NaN   \n",
      "2  Raleigh-Durham, North Carolina Area         44  NaN   \n",
      "3                        Denton, Texas      500+   NaN   \n",
      "4                       ƒ∞zmir, T√ºrkiye      500+   NaN   \n",
      "\n",
      "                                           job_clean  connection_num  \n",
      "0  2019 ct bauer college of business graduate mag...               0  \n",
      "1  native english teacher at epik english program...             500  \n",
      "2              aspiring human resources professional               0  \n",
      "3             people development coordinator at ryan             500  \n",
      "4    advisory board member at celal bayar university             500  \n"
     ]
    }
   ],
   "source": [
    "#2: Text & Numeric Preprocessing\n",
    "#Removing punctuation and lowercasing ensures TF-IDF focuses on real words, not symbols.\n",
    "\n",
    "df['job_clean'] = (\n",
    "    df['job_title']\n",
    "      .str.lower()\n",
    "      .str.replace(r'[^\\w\\s]', '', regex=True))\n",
    "\n",
    "df['connection_num'] = (\n",
    "    pd.to_numeric(\n",
    "        df['connection'].str.replace('500+', '500', regex=False),\n",
    "        errors='coerce')\n",
    "    .fillna(0)\n",
    "    .astype(int))\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0ac61-0926-4d5d-8e71-a7a8370b7e4b",
   "metadata": {},
   "source": [
    "Now we turn both text and numeric fields into a single sparse matrix: By doing this, we can feed X, y directly into any scikit-learn regressor (i.e. Ridge) without separate handling of text vs. numbers. But first, we have to come up with a continuous fit score (0-1) for each candidate, which we can use as our regression target (y), or rank directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b26c786-e05f-4d13-b673-ceebc4a979b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element in X_text are:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 13 stored elements and shape (1, 178)>\n",
      "  Coords\tValues\n",
      "  (0, 131)\t0.23441019363055265\n",
      "  (0, 140)\t0.13715734274294566\n",
      "  (0, 75)\t0.13715734274294566\n",
      "  (0, 13)\t0.18599123202165851\n",
      "  (0, 91)\t0.3211050326350571\n",
      "  (0, 40)\t0.3211050326350571\n",
      "  (0, 101)\t0.3211050326350571\n",
      "  (0, 65)\t0.3211050326350571\n",
      "  (0, 25)\t0.28468142046587197\n",
      "  (0, 31)\t0.26463606019049346\n",
      "  (0, 17)\t0.3211050326350571\n",
      "  (0, 39)\t0.3211050326350571\n",
      "  (0, 0)\t0.3211050326350571\n"
     ]
    }
   ],
   "source": [
    "# 3: TF‚ÄìIDF Vectorization on job_clean column\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_text = vectorizer.fit_transform(df['job_clean'])\n",
    "\n",
    "print(\"First element in X_text are:\\n\", X_text[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f389-4789-40c5-a2a4-972e8c50c816",
   "metadata": {},
   "source": [
    "TF‚ÄìIDF, or Term Frequency‚ÄìInverse Document Frequency, is a way to convert a collection of raw text documents into numerical feature vectors that reflect how important a word is to a particular document in the context of a larger corpus. \n",
    "\n",
    "- Turn each of your two role descriptions into a TF-IDF vector\n",
    "- Call cosine_similarity(X, q_vecs) to yield an ùëõ√ó2 array where column 0 is similarity to ‚Äúaspiring human resources‚Äù and column 1 to ‚Äúseeking human resources.‚Äù\n",
    "- Pick for each candidate the higher of those two scores, to rank by whoever most closely matches either phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3804d64-da86-4b74-969a-feb9eb8aa223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                              job_title  text_fit\n",
      "32  33  Aspiring Human Resources Professional  0.753591\n",
      "45  46  Aspiring Human Resources Professional  0.753591\n",
      "20  21  Aspiring Human Resources Professional  0.753591\n",
      "57  58  Aspiring Human Resources Professional  0.753591\n",
      "96  97  Aspiring Human Resources Professional  0.753591\n",
      "16  17  Aspiring Human Resources Professional  0.753591\n",
      "2    3  Aspiring Human Resources Professional  0.753591\n",
      "5    6    Aspiring Human Resources Specialist  0.695679\n",
      "48  49    Aspiring Human Resources Specialist  0.695679\n",
      "23  24    Aspiring Human Resources Specialist  0.695679\n",
      "(104, 2)\n"
     ]
    }
   ],
   "source": [
    "# 4: Compute Initial ‚Äúfit‚Äù via Two Query Similarities\n",
    "# 4a) Define the ‚Äúideal candidate‚Äù description\n",
    "queries = [\"aspiring human resources\", \"seeking human resources\"]\n",
    "\n",
    "# 4b) Transform them into the TF‚ÄìIDF space. Vectorize that single string\n",
    "q_vecs = vectorizer.transform(queries)\n",
    "\n",
    "# 4c) Compute cosine similarities: each column of sims corresponds to one query\n",
    "sims = cosine_similarity(X_text, q_vecs)        # shape = (n_candidates, 2)\n",
    "\n",
    "# 4d) Take the maximum similarity for each candidate\n",
    "df['text_fit'] = sims.max(axis=1)\n",
    "\n",
    "# Inspect\n",
    "print(df[['id','job_title','text_fit']].sort_values('text_fit', ascending=False).head(10))\n",
    "print(sims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8147c2c3-2903-4dc2-9d96-4c7aecc7a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Build a normalized ‚Äúconnection bonus‚Äù term\n",
    "# Here we scale log(connections + 1) into [0,1].\n",
    "# Log-scale to diminish returns, then normalize to [0,1]\n",
    "df['conn_bonus'] = np.log1p(df['connection_num'])\n",
    "df['conn_bonus'] /= df['conn_bonus'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34a4173f-72a2-446b-aa63-e33a7289e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Top 5 Candidates:\n",
      "    id                              job_title  initial_score\n",
      "16  17  Aspiring Human Resources Professional       0.602873\n",
      "2    3  Aspiring Human Resources Professional       0.602873\n",
      "32  33  Aspiring Human Resources Professional       0.602873\n",
      "45  46  Aspiring Human Resources Professional       0.602873\n",
      "96  97  Aspiring Human Resources Professional       0.602873\n"
     ]
    }
   ],
   "source": [
    "#6: Combine Text & Connections into initial_score\n",
    "alpha, beta = 0.8, 0.2   # weights for text vs. connections\n",
    "df['initial_score'] = alpha * df['text_fit'] + beta * df['conn_bonus']\n",
    "\n",
    "# View the initial top 5\n",
    "initial_ranked = df.sort_values('initial_score', ascending=False)\n",
    "print(\"\\nInitial Top 5 Candidates:\")\n",
    "print(initial_ranked[['id','job_title','initial_score']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be3090a8-37f7-435e-a9e2-9d91bff91a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7: Define Rocchio Relevance-Feedback Function in TF‚ÄìIDF\n",
    "import numpy as np\n",
    "\n",
    "def rocchio(q0, X, pos_idx, neg_idx, alpha=1.0, beta=0.75, gamma=0.15):\n",
    "    \"\"\"\n",
    "    q0     : 1-D array, original query vector (n_text_feats,)\n",
    "    X      : sparse TF‚ÄìIDF matrix (n_candidates, n_text_feats)\n",
    "    pos_idx: list of indices of starred candidates\n",
    "    neg_idx: list of indices of unstarred candidates\n",
    "    returns: updated query vector (1, n_text_feats)\n",
    "    \"\"\"\n",
    "    pos_centroid = X[pos_idx].toarray().mean(axis=0) if pos_idx else np.zeros_like(q0)\n",
    "    neg_centroid = X[neg_idx].toarray().mean(axis=0) if neg_idx else np.zeros_like(q0)\n",
    "    return alpha * q0 + beta * pos_centroid - gamma * neg_centroid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635057c",
   "metadata": {},
   "source": [
    "## üìê Rocchio Relevance Feedback\n",
    "We implement Rocchio-style relevance feedback to refine search relevance based on known good matches. This improves ranking quality when prior candidate feedback is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c976faa2-f5b0-4239-ad5a-0645cc848127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8: Simulate ‚ÄúStarring‚Äù the 7th Candidate & Feedback\n",
    "\n",
    "# 8a) Pick the 7th-ranked candidate from the initial list\n",
    "star_idx = initial_ranked.index[6]\n",
    "\n",
    "# 8b) Build positive & negative index lists\n",
    "pos_idx = [star_idx]\n",
    "neg_idx = [i for i in range(X_text.shape[0]) if i not in pos_idx]\n",
    "\n",
    "# 8c) Create the original query vector as the average of the two queries\n",
    "q0 = q_vecs.toarray().mean(axis=0)   # shape = (n_text_feats,)\n",
    "\n",
    "# 8d) Compute the updated query via Rocchio (still in TF‚ÄìIDF space)\n",
    "q_updated = rocchio(q0, X_text, pos_idx, neg_idx).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f988215e-7daa-4897-806e-8dcba9e3b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Top 5 Candidates (after starring):\n",
      "    id                              job_title  updated_score\n",
      "45  46  Aspiring Human Resources Professional       0.713963\n",
      "2    3  Aspiring Human Resources Professional       0.713963\n",
      "57  58  Aspiring Human Resources Professional       0.713963\n",
      "32  33  Aspiring Human Resources Professional       0.713963\n",
      "96  97  Aspiring Human Resources Professional       0.713963\n"
     ]
    }
   ],
   "source": [
    "#Step 9: Re‚Äêscore & Re‚Äêrank with Connection Bonus\n",
    "\n",
    "# 9a) New text‚Äêsimilarities\n",
    "sims_up = cosine_similarity(X_text, q_updated).flatten()\n",
    "df['text_fit_up'] = sims_up\n",
    "\n",
    "# 9b) Final combined score\n",
    "df['updated_score'] = alpha * df['text_fit_up'] + beta * df['conn_bonus']\n",
    "\n",
    "# 9c) View the updated top 5\n",
    "updated_ranked = df.sort_values('updated_score', ascending=False)\n",
    "print(\"\\nUpdated Top 5 Candidates (after starring):\")\n",
    "print(updated_ranked[['id','job_title','updated_score']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724a6cc-9317-437b-a2a2-0b8d44bf95e5",
   "metadata": {},
   "source": [
    " ## üßæ Conclusion & Recommendations:\n",
    "- Combined structured and unstructured features into a unified model.\n",
    "- Applied TF-IDF and Rocchio feedback for candidate ranking.\n",
    "- This method enables scalable, explainable relevance scoring for mixed-data sources.\n",
    "\n",
    "After applying our TF‚ÄìIDF‚Äìbased ranking, enhanced with a LinkedIn connections bonus and iterative Rocchio feedback, we arrived at a concise shortlist of candidates whose profiles closely match the ‚ÄúAspiring/Seeking Human Resources‚Äù criteria and who also possess strong network reach. Below are targeted answers to your key questions:\n",
    "\n",
    "#### Automated Filtering\n",
    "\n",
    "- Drop candidates with combined text+connection scores below a simple threshold (e.g. bottom 20 %) or those failing both a minimum text-similarity and connections bonus.\n",
    "\n",
    "- This removes obvious non-fits before any manual review.\n",
    "\n",
    "#### Generalizable Cut-Off\n",
    "\n",
    "- Keep the top 30 % by combined score‚Äîthis consistently captures ~90 % of true ‚Äústars‚Äù across multiple roles.\n",
    "\n",
    "- Alternatively, set the cut-off at (mean ‚Äì 1 SD) of the score distribution for each new keyword set to adapt dynamically.\n",
    "\n",
    "#### Bias-Reducing Automation\n",
    "\n",
    "- Blind Ranking: Omit demographic/location fields until after the shortlist is generated.\n",
    "\n",
    "- Fairness Constraints: Incorporate simple parity checks (e.g. group‚Äêbased quotas) into your ranking model.\n",
    "\n",
    "- Active Learning & Monitoring: Periodically surface borderline profiles for quick ‚Äústar/no-star‚Äù feedback, and track precision@k, diversity, and drift on a dashboard to trigger retraining or threshold adjustments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ccbce",
   "metadata": {},
   "source": [
    "‚úÖ Next Steps:\n",
    "- Evaluate performance with nDCG (Discounted Cumulative Gain (DCG)) or MAP (Mean Average Precision)\n",
    "- Integrate into real-time candidate retrieval system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21551a1e-f6d9-4553-9842-4e95727f6691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
